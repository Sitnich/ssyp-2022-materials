{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "day2_data_and_regression_full.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GeqjUsgn4HY"
      },
      "source": [
        "# Линейная регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сегодня мы попытаемся смоделировать задачу линейной регрессии на датасете boston.csv. Этот датасет представляет собой таблицу, в которой в каждой строке находится информация о стоимости дома в Бостоне, а также численные признаки, которые на эту стоимость могут влиять. Эти признаки на английском объясняются так:\n",
        "\n",
        "  1. crim:     per capita crime rate by town\n",
        "  2. zn:       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "  3. indus:    proportion of non-retail business acres per town\n",
        "  4. chas:     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "  5. nox:      nitric oxides concentration (parts per 10 million)\n",
        "  6. rm:       average number of rooms per dwelling\n",
        "  7. age:      proportion of owner-occupied units built prior to 1940\n",
        "  8. dis:      weighted distances to five Boston employment centres\n",
        "  9. rad:      index of accessibility to radial highways\n",
        "  10. tax:      full-value property-tax rate per 10,000 dollars\n",
        "  11. ptratio:  pupil-teacher ratio by town\n",
        "  12. b:        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "  13. lstat:    % lower status of the population\n",
        "\n",
        "И последним признаком в таблице идет стоимость дома:\n",
        "\n",
        "  14. medv:     median value of owner-occupied homes in $'s\n",
        "\n",
        "Их необязательно полностью понимать, но если интересно - можно пользоваться google переводчиком или подзывать меня :)\n"
      ],
      "metadata": {
        "id": "isXzYgM0HKUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы формулируем задачу линейной регрессии так: мы хотим построить зависимость  $Y = w_1 X_1 + w_2 X_2 + ... + w_{14} X_{14}$, где $Y$ - это стоимость дома, $X_i$ - это переменные соответствующие признакам, а $W_i$ - коэффициенты, на которые эти признаки умножаются. Мы хотим найти коэффициенты $W_i$ так, чтобы получаемое по формуле значение Y было максимально близко к истинной цене дома. Интуитивно это понимается так: рассмотрим первый признак с названием crim. В нем хранится число - вероятность совершения преступления в районе, в котором находится дом. Логично, что цена дома если это показатель высок, будет низкой - никто не хочет жить в криминальном районе. Таким образом, вероятнее всего после построения модели линейной регрессии мы получим коэффициент w_1 как отрицательное число (т.е. первый признак влияет на цену с обратной зависимостью: чем больше значение переменной, тем меньше значение Y (таргета))."
      ],
      "metadata": {
        "id": "FvRvvlzpJoPp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmYMrZJGn4Hg"
      },
      "source": [
        "from sklearn.datasets import make_blobs, make_moons\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt # библиотеки для построения графиков\n",
        "import matplotlib\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\") # чтобы загружать файлы с гугл диска\n",
        "\n",
        "path = \"/content/gdrive/My Drive/boston.csv\" # здесь укажите свой путь до boston.csv\n",
        "                                             # (датасет должен лежать на гугл диске)"
      ],
      "metadata": {
        "id": "OdeSq5K3Ni7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сперва реализуем функцию для считывания датасета boston.csv. Мне нужно чтобы вы самостоятельно изучили датасет (я кинула его в тг), считали его с помощью метода np.genfromtxt (при этом нужно пропустить первые 15 строк); затем его нужно перемешать (вспомните методы из модуля random cо вчера).\n",
        "Метод должен возвращать два np.ndarray: один со всеми признаками (цена дома - НЕ признак, это таргет который мы будем предсказывать), второй ndarray должен как раз содержать стоимости домов."
      ],
      "metadata": {
        "id": "sKVNUHuIMX-4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l86n1A9Bn4Hj"
      },
      "source": [
        "def read_data(path_to_csv=path):\n",
        "    \"\"\"\n",
        "     \n",
        "    Parameters\n",
        "    ----------\n",
        "    path_to_csv : str\n",
        "        Путь к cancer датасету.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : np.array\n",
        "        Матрица признаков (её размер должен быть: (количество домов)x(количество признаков)).\n",
        "    y : np.array\n",
        "        Вектор цен домов (размер: (количество домов)).\n",
        "\n",
        "    \n",
        "    return X, y\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начиная работать с данными, нам необходимо их предобработать и подготовить. В частности, нам необходимо разделить выборку на две: тренировочную и тестовую. Тренировочная выборка необходима для обучения алгоритма, а тестовая для проверки результатов обучения. Обычно используют коэффициент разделения `0.9`.\n",
        "\n",
        "Необходимо вернуть кортеж из `X_train`, `y_train`, `X_test` и `y_test`"
      ],
      "metadata": {
        "id": "ZPxJXU1DQLOZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwizrVYIG5S9"
      },
      "outputs": [],
      "source": [
        "def train_test_split(X: np.array, y: np.array, ratio: float):\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : np.array\n",
        "        Матрица признаков.\n",
        "    y : np.array\n",
        "        Вектор меток.\n",
        "    ratio : float\n",
        "        Коэффициент разделения.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_train : np.array\n",
        "        Матрица признаков для train выборки.\n",
        "    y_train : np.array\n",
        "        Вектор меток для train выборки.\n",
        "    X_test : np.array\n",
        "        Матрица признаков для test выборки.\n",
        "    y_test : np.array\n",
        "        Вектор меток для test выборки.\n",
        "\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метод для заполнения весов модели рандомными значениями."
      ],
      "metadata": {
        "id": "tCqvu6DnOpM6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIDuGR68n4Hj"
      },
      "source": [
        "def generate_synthetic(size:int, dim=6, noise=0.1):\n",
        "    X = np.random.randn(size, dim)\n",
        "    w = np.random.randn(dim + 1)\n",
        "    noise = noise * np.random.randn(size)\n",
        "    y = X.dot(w[1:]) + w[0] + noise\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTQrXJM3n4Hk"
      },
      "source": [
        "Давайте поймем, какую метрику для ошибки будем использовать. В нашем случае нам подойдет стандартная метрика MSE. Также чтобы оценить качество модели нам понадобится метрика $R^2$. Реализуйте обе эти метрики."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhFj_POqn4Hl"
      },
      "source": [
        "def mse(y_true:np.ndarray, y_predicted:np.ndarray):\n",
        "    return 0.0\n",
        "\n",
        "def r2(y_true:np.ndarray, y_predicted:np.ndarray):\n",
        "    return 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl6-3k-wn4Hm"
      },
      "source": [
        "Теперь реализуем линейную регрессию при помощи явного решения задачи минимизации. \n",
        "\n",
        "#### Методы\n",
        "`fit(X, y)` - решает задачу минимизации $\\arg\\min_{w, b}\\sum ((w\\cdot x + b) - y)^2$. \n",
        "\n",
        "`predict(X)` - строит предсказание `y` для объектов из `X`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ5qQ1p3n4Hn"
      },
      "source": [
        "class NormalLR:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def fit(self, X:np.ndarray, y:np.ndarray):\n",
        "        pass\n",
        "    \n",
        "    def predict(self, X:np.ndarray) -> np.ndarray:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg5BqJPAn4Hn"
      },
      "source": [
        "X, y = generate_synthetic(1024)\n",
        "X_train, y_train, X_test, y_test = train_test_split(X, y, ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyB5sun8n4Ho"
      },
      "source": [
        "regr = NormalLR()\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "print(f\"MSE: {mse(y_test, y_pred)}, R2: {r2(y_test, y_pred)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ9rFp-gn4Hp"
      },
      "source": [
        "### Если вы чувствуете в себе уверенность (или не знаете чем заняться)\n",
        "Реализуем линейную регрессию с использованием градиентного спуска с larning rate `alpha` в течении `iterations` итераций. В задании необходимо использовать регуляризацию Лассо с коэффициентом `l`.\n",
        "\n",
        "#### Методы\n",
        "`fit(X, y)` - приближает решение задачи минимизации $\\arg\\min_{w, b}\\sum ((w\\cdot x + b) - y)^2$ при помощи градиентного спуска. \n",
        "\n",
        "\n",
        "`predict(X)` - строит предсказание `y` для объектов из `X`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYzw2-dcn4Hq"
      },
      "source": [
        "class GradientLR:\n",
        "    def __init__(self, alpha:float, iterations=10000, l=0.):\n",
        "        pass\n",
        "    \n",
        "    def fit(self, X:np.ndarray, y:np.ndarray):\n",
        "        pass\n",
        "\n",
        "    def predict(self, X:np.ndarray):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcfjGBREn4Hq"
      },
      "source": [
        "def build_plot(X_train, y_train, X_test, y_test):\n",
        "    xs = np.arange(0.0, 0.002, 0.00002)\n",
        "    errors = []\n",
        "    for x in xs:\n",
        "        regr = GradientLR(0.1, iterations=10000, l=x)\n",
        "        regr.fit(X_train, y_train)\n",
        "        errors.append(mse(y_test, regr.predict(X_test)))\n",
        "    plt.figure(figsize=(9, 4))\n",
        "    plt.xlim(xs[0], xs[-1])\n",
        "    plt.grid()\n",
        "    plt.plot(xs, errors)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ8txzZdn4Hr"
      },
      "source": [
        "X, y = generate_synthetic(1024)\n",
        "X, X_val, y, y_val = train_test_split(X, y, ratio=0.9, shuffle=True)\n",
        "X_train, y_train, X_test, y_test = train_test_split(X, y, ratio=0.8, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7QFa1czn4Hs"
      },
      "source": [
        "build_plot(X_train, y_train, X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siP8OKLRn4Ht"
      },
      "source": [
        "regr = GradientLR(0.1, iterations=10000)\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "print(f\"MSE: {mse(y_test, y_pred)}, R2: {r2(y_test, y_pred)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmjSHt9rn4Ht"
      },
      "source": [
        "\n",
        "Протесируйте оба метода на данных `boston.csv`, для градиентного спуска постройте график зависимости ошибки от коэффициента регуляризации. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk2TeC7Hn4Hu"
      },
      "source": [
        "X, y = read_data()\n",
        "X_train, y_train, X_val, y_val = train_test_split(X, y, train_size=0.8, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZCb_5KVn4Hu"
      },
      "source": [
        "regr = NormalLR()\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_val)\n",
        "w=regr.w\n",
        "\n",
        "print(f\"MSE: {mse(y_val, y_pred)}, R2: {r2(y_test, y_val)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMkUfayxn4Hv"
      },
      "source": [
        "build_plot(X_train, y_train, X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtPBlBPkn4Hw"
      },
      "source": [
        "regr = GradientLR(0.1, iterations=10000)\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_val)\n",
        "\n",
        "print(f\"MSE: {mse(y_val, y_pred)}, R2: {r2(y_test, y_val)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d63Ei1yEn4Hw"
      },
      "source": [
        "\n",
        "Проинтерпритируйте полученные результаты. Опишите влияние каждого признака на результат предсказания."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path) as myfile:\n",
        "    head = [next(myfile) for x in range(14)]\n",
        "for i in range(13):\n",
        "    print('{} : {}'.format(w[i+1],head[i]),end='')"
      ],
      "metadata": {
        "id": "Pq-S5KxCZb8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "пишем тут"
      ],
      "metadata": {
        "id": "jsCDRJUBImJA"
      }
    }
  ]
}